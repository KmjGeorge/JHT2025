1、PDW Norm  √
2、测试集 √
3、metrics   √
4、配套配置文件 √
5、更好的Loss和网络架构 ○
   辐射源个数较少时的增批问题（arXiv:2503.13476v1)
6、长序列训练
   旋转位置编码
7、loss计算优化 √
8、添加CELoss的版本 与原版对比     加入CELoss更优  √
9、添加片段级Loss的版本，与片段的聚类中心比    →   进一步拓展到SwAV的思想
                                            再添加一个线性头用于输出原型 (bias=False)
10、添加L1 Loss的版本 需改变数据集  ○


10.20开始要干的事情
1、python版数据生成脚本       混合：漏脉冲率是连续值吗
2、测试引入片段级loss    √
3、测试不使用RoPE
4、长序列、大宽度的版本
5、如果必须分段推理，需要进行段间结果合并  √
   策略：a. 每段聚类，合并标签
           方案① 找到每段聚类结果中的所有簇质心，后一段的每个簇找到与前一段最接近的质心，视为同一个标签。如果与所有质心距离都超过阈值，加入到新的类
           方案② 对所有簇质心进行提取，然后对质心进行再聚类。聚类结果分配到原始数据中
        b. 拼接多段特征，然后一次性聚类    √
6、局部性，窗口注意力
7、负样本自适应采样   √
   测试基于cos相似度的采样
   前期使用topk采样加快收敛速度，后期随机采样避免只优化少数几个样本

8、考虑采取MoE用于不同场景的自适应
9、推理时输出特征的L2归一化  √
   最后的头加入非线性 √

# 11、考虑两个方案：① Reformer + ALiBi直接外推
#               ② Reformer + RoPE 然后分窗口推理
10、咋回事啊Autoformer
   TimesNet
11、Cos学习率
12、原型正负样本  T=0.05  running   性能有一定下降，但大幅加快训练速度


结论:
1、Loss实现2：不要使用 (B*N, C)采样 因为batch内每个数据是按自身归一化的，依然需要遍历batch
2、只使用DTOA更好
3、Point Seg  0.9 : 0.1有用
4、训练前阶段使用CE，后阶段只使用InfoNCE
5、T=0.2 < T=0.1 < T=0.05
6、前期使用topk采样加快收敛速度，后期随机采样避免只优化少数几个样本


！！！！！！！！！！！！！！！！！换新数据记得改label_map (data_util.py) ！！！！！！！！！！！！！！！
使用read_pdw_new_recog  和PDWTrain_new
修改原型的label_num